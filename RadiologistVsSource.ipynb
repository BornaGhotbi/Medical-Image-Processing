{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from collections import defaultdict, OrderedDict\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/var/data/processed'\n",
    "GOLDEN_ROOT = os.path.join(DATA_ROOT, 'golden')\n",
    "CSV_DATA_ENTRY = os.path.join(GOLDEN_ROOT, 'Data_Entry_Golden.csv')\n",
    "CSV_DIRECTORY_REFERENCE = os.path.join(GOLDEN_ROOT, 'randomized_lut.csv')\n",
    "CSV_DIRECTORY_FILLED = os.path.join(GOLDEN_ROOT, 'filled','RandomizedImages1.filled100.csv')\n",
    "ORIGINAL_IMAGES_DIR = '/var/data/original/data/images'\n",
    "GOLDEN_IMAGES_DIR = os.path.join(GOLDEN_ROOT, 'images')\n",
    "GOLDEN100_CSV_DIR = os.path.join(GOLDEN_ROOT, 'golden100.csv')\n",
    "GOLDEN100__JSON_DIR = os.path.join(GOLDEN_ROOT, 'golden100.json')\n",
    "GOLDEN100_SOURCE__JSON_DIR = os.path.join(GOLDEN_ROOT, 'golden_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPT_NAME = 'expt_001'\n",
    "EXPT_DIR = os.path.join(DATA_ROOT, EXPT_NAME, 'data')\n",
    "EMBEDDINGS_DIR = os.path.join(EXPT_DIR, 'embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for doc in documents:\\n    doc['mu'] = np.asarray(doc['mu'])\\n    doc['sigma'] = np.asarray(doc['sigma'])\\n    doc['labels'] = np.asarray(doc['labels'])\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "golden_documents = []\n",
    "json_files = [pos_json for pos_json in os.listdir(EMBEDDINGS_DIR) if pos_json.endswith('.json')]\n",
    "for file in json_files:\n",
    "    path = os.path.join(EMBEDDINGS_DIR, file)\n",
    "    with open(path) as f:\n",
    "        doc = json.load(f)\n",
    "        if (doc['subset'] == 'golden'):\n",
    "            golden_documents.append(doc)\n",
    "\n",
    "val_documents = []\n",
    "json_files = [pos_json for pos_json in os.listdir(EMBEDDINGS_DIR) if pos_json.endswith('.json')]\n",
    "for file in json_files:\n",
    "    path = os.path.join(EMBEDDINGS_DIR, file)\n",
    "    with open(path) as f:\n",
    "        doc = json.load(f)\n",
    "        if (doc['subset'] == 'golden'):\n",
    "            val_documents.append(doc)            \n",
    "\n",
    "'''for doc in documents:\n",
    "    doc['mu'] = np.asarray(doc['mu'])\n",
    "    doc['sigma'] = np.asarray(doc['sigma'])\n",
    "    doc['labels'] = np.asarray(doc['labels'])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hashtable mapping source filenames to source labels.\n",
    "\n",
    "csvfile =  open(CSV_DATA_ENTRY) \n",
    "filename_to_source_labels = defaultdict(list)\n",
    "row_count = sum(1 for row in csv.reader(csvfile))\n",
    "csvfile =  open(CSV_DATA_ENTRY) \n",
    "\n",
    "LABEL_KEYS = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"No Finding\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "]\n",
    "\n",
    "nb_label_keys = len(LABEL_KEYS)\n",
    "label_keys_by_id = LABEL_KEYS\n",
    "ids_by_label_key = OrderedDict([(v, k) for k, v in enumerate(label_keys_by_id)])\n",
    "\n",
    "# Iterate through file; represent labels as N-hot binary lists\n",
    "for i,line in enumerate(csvfile.readlines()[1:row_count]):\n",
    "    \n",
    "    tokens = line.strip().split(',')\n",
    "    labels = []\n",
    "\n",
    "    for key in tokens[1].split('|'):\n",
    "        labels.append(key)\n",
    "    \n",
    "    filename_to_source_labels[tokens[0]].append(labels)   \n",
    "    \n",
    "def getlabels(onehot_labels):\n",
    "    list = []\n",
    "    for index_value, index in enumerate(onehot_labels):\n",
    "        if(index == 1):\n",
    "            list.append(ids_by_label_key.get(index_value))\n",
    "\n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import OrderedDict\\nLABEL_KEYS2 = [\\n    \"Atelectasis\",\\n    \"Cardiomegaly\",\\n    \"Consolidation\",\\n    \"Edema\",\\n    \"Effusion\",\\n    \"Emphysema\",\\n    \"Fibrosis\",\\n    \"Hernia\",\\n    \"Infiltration\",\\n    \"Mass\",\\n    \"Nodule\",\\n    \"Pleural_Thickening\",\\n    \"Pneumonia\",\\n    \"Pneumothorax\",\\n    \"No Finding\", \\n]\\n\\nlabel_keys_by_id = LABEL_KEYS2\\nids_by_label_key2 = OrderedDict([(k,v) for k, v in enumerate(label_keys_by_id)])\\n  \\ndef getlabels(onehot_labels):\\n    list = []\\n    for index_value, index in enumerate(onehot_labels):\\n        if(index == 1):\\n            list.append(ids_by_label_key2.get(index_value))\\n\\n    return list'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import OrderedDict\n",
    "LABEL_KEYS2 = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "    \"No Finding\", \n",
    "]\n",
    "\n",
    "label_keys_by_id = LABEL_KEYS2\n",
    "ids_by_label_key2 = OrderedDict([(k,v) for k, v in enumerate(label_keys_by_id)])\n",
    "  \n",
    "def getlabels(onehot_labels):\n",
    "    list = []\n",
    "    for index_value, index in enumerate(onehot_labels):\n",
    "        if(index == 1):\n",
    "            list.append(ids_by_label_key2.get(index_value))\n",
    "\n",
    "    return list'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hash table mapping id numbers to filenames for 100 golden data\n",
    "csvfile =  open(CSV_DIRECTORY_REFERENCE) \n",
    "index = defaultdict(list)\n",
    "for line in csvfile.readlines():\n",
    "    tokens = line.strip().split(',')\n",
    "    index[tokens[0]].append(tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new csv file for the 100 golden data out of 400 csv file\n",
    "\n",
    "filenames_golden = []\n",
    "\n",
    "i = 0\n",
    "for value in index.values():\n",
    "    if(i != 100):\n",
    "        filenames_golden.append(value[0])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "csvfile_read =  open(CSV_DATA_ENTRY) \n",
    "\n",
    "\n",
    "csvfile_write =  open(GOLDEN100_CSV_DIR, 'w') \n",
    "write_lines = \"\"\n",
    "\n",
    "\n",
    "for i,line in enumerate(csvfile_read.readlines()):\n",
    "\n",
    "    if(i==0):\n",
    "        csvfile_write.write(line)\n",
    "\n",
    "    tokens = line.strip().split(',')\n",
    "    \n",
    "    if tokens[0] in filenames_golden:\n",
    "        csvfile_write.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a hash table mapping filenames to radiologist labels. \n",
    "#create json for radiologist id, filename, labels, and other  \n",
    "\n",
    "csvfile =  open(CSV_DIRECTORY_FILLED) \n",
    "radiologist_csvtokens = []\n",
    "row_count = sum(1 for row in csv.reader(csvfile))\n",
    "csvfile =  open(CSV_DIRECTORY_FILLED) \n",
    "filename_to_radiologist_labels = defaultdict(list)\n",
    "filename_to_radiologist_labels_onehot = defaultdict(list)\n",
    "\n",
    "\n",
    "# Iterate through file; represent labels as N-hot binary lists\n",
    "for i,line in enumerate(csvfile.readlines()[1:(row_count-2)]):\n",
    "    \n",
    "    tokens = line.strip().split(',')\n",
    "    onehot_labels = np.zeros(15).astype(int)\n",
    "    \n",
    "    for i,key in enumerate(tokens[1:12]):\n",
    "        if(key == 'x'):\n",
    "            onehot_labels[i] = 1\n",
    "    if(tokens[12] == 'x'):\n",
    "        onehot_labels[12] = 1\n",
    "    if(tokens[13] == 'x'):\n",
    "        onehot_labels[13] = 1\n",
    "    if(tokens[14] == 'x'):\n",
    "        onehot_labels[14] = 1\n",
    "    if(tokens[15] == 'x'):\n",
    "        onehot_labels[11] = 1\n",
    "    \n",
    "    filename_to_radiologist_labels[index[tokens[0]][0]].append(getlabels(onehot_labels))\n",
    "    filename_to_radiologist_labels_onehot[index[tokens[0]][0]].append(onehot_labels)\n",
    "    \n",
    "    radiologist_csvtokens.append({\n",
    "        'id': tokens[0],\n",
    "        'filename': index[tokens[0]],\n",
    "        'labels': getlabels(onehot_labels),\n",
    "        'other': tokens[16]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the golden100_source.json file based on the labels we got from the source\n",
    "\n",
    "csvfile_read =  open(GOLDEN100_CSV_DIR, 'r') \n",
    "json_lines = []\n",
    "\n",
    "csvfile_read.readline()\n",
    "for line in enumerate(csvfile_read.readlines()):\n",
    "\n",
    "    tokens = line[1].strip().split(',')\n",
    "    labels = [0]*nb_label_keys\n",
    "    \n",
    "    for key in tokens[1].split('|'):\n",
    "        labels[ids_by_label_key[key]] = 1\n",
    "            \n",
    "    json_lines.append({\n",
    "        'filename': tokens[0],\n",
    "        'labels': labels,\n",
    "        'age':tokens[4],\n",
    "        'gender': tokens[5],\n",
    "        'view': tokens[6],\n",
    "        'dx': float(tokens[9]),\n",
    "        'dy': float(tokens[10]),\n",
    "        'w': int(tokens[7]),\n",
    "        'h': int(tokens[8]),\n",
    "    })\n",
    "\n",
    "        \n",
    "with open(GOLDEN100__JSON_DIR, 'w') as outfile:\n",
    "        json.dump(json_lines, outfile, separators=(',', ':'), indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the golden100.json file based on the labels we got from the source\n",
    "\n",
    "csvfile_read =  open(GOLDEN100_CSV_DIR, 'r') \n",
    "json_lines = []\n",
    "labels = []\n",
    "csvfile_read.readline()\n",
    "for line in enumerate(csvfile_read.readlines()):\n",
    "\n",
    "    tokens = line[1].strip().split(',')\n",
    "    json_lines.append({\n",
    "        'filename': tokens[0],\n",
    "        'labels': filename_to_radiologist_labels_onehot[tokens[0]][0].tolist(),\n",
    "        'age':tokens[4],\n",
    "        'gender': tokens[5],\n",
    "        'view': tokens[6],\n",
    "        'dx': float(tokens[9]),\n",
    "        'dy': float(tokens[10]),\n",
    "        'w': int(tokens[7]),\n",
    "        'h': int(tokens[8]),\n",
    "    })\n",
    "\n",
    "        \n",
    "with open(GOLDEN100_SOURCE__JSON_DIR, 'w') as outfile:\n",
    "        json.dump(json_lines, outfile, separators=(',', ':'), indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            Radiologist                                                          Source                    \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "000001      No Finding,                                               No Finding,                   \n",
      "000002      Atelectasis,Effusion,Hernia,Pleural_Thickening,           Fibrosis,Hernia,              \n",
      "000003                                                                Atelectasis,                  \n",
      "000004      No Finding,                                               Nodule,                       \n",
      "000005      No Finding,                                               No Finding,                   \n",
      "000006                                                                No Finding,                   \n",
      "000007      Consolidation,Infiltration,                               Effusion,Infiltration,        \n",
      "000008      No Finding,                                               No Finding,                   \n",
      "000009      Atelectasis,Consolidation,Effusion,Pleural_Thickening,    Emphysema,Pleural_Thickening, \n",
      "000010      No Finding,                                               No Finding,                   \n",
      "000011      Cardiomegaly,                                             Atelectasis,Consolidation,    \n",
      "000012      Atelectasis,                                              No Finding,                   \n",
      "000013      No Finding,                                               No Finding,                   \n",
      "000014      No Finding,                                               No Finding,                   \n",
      "000015      Infiltration,                                             Consolidation,Infiltration,   \n",
      "000016      Edema,                                                    No Finding,                   \n",
      "000017      Fibrosis,                                                 Edema,                        \n",
      "000018      Consolidation,Edema,Effusion,                             No Finding,                   \n",
      "000019      Atelectasis,Effusion,Fibrosis,                            Effusion,                     \n",
      "000020      Infiltration,                                             Infiltration,                 \n",
      "000021                                                                No Finding,                   \n",
      "000022      No Finding,                                               No Finding,                   \n",
      "000023      No Finding,                                               No Finding,                   \n",
      "000024      Atelectasis,Effusion,Pleural_Thickening,Pneumothorax,     Emphysema,                    \n",
      "000025      Edema,Effusion,                                           Effusion,                     \n",
      "000026      No Finding,                                               Nodule,                       \n",
      "000027      Atelectasis,Consolidation,Effusion,Mass,                  No Finding,                   \n",
      "000028      Consolidation,Effusion,Pleural_Thickening,Pneumothorax,   Emphysema,Pneumothorax,       \n",
      "000029      Atelectasis,Cardiomegaly,Effusion,                        No Finding,                   \n",
      "000030      No Finding,                                               No Finding,                   \n",
      "000031      No Finding,                                               Infiltration,                 \n",
      "000032      Consolidation,Infiltration,                               Infiltration,                 \n",
      "000033      Cardiomegaly,                                             Infiltration,                 \n",
      "000034      No Finding,                                               Fibrosis,                     \n",
      "000035      Effusion,                                                 Pneumothorax,                 \n",
      "000036                                                                No Finding,                   \n",
      "000037      Atelectasis,Fibrosis,Hernia,                              No Finding,                   \n",
      "000038      Atelectasis,Effusion,Infiltration,Mass,                   Effusion,Infiltration,Mass,Pleural_Thickening,\n",
      "000039      Atelectasis,Effusion,Pleural_Thickening,                  No Finding,                   \n",
      "000040      Atelectasis,Effusion,Pleural_Thickening,Pneumothorax,     Atelectasis,Emphysema,        \n",
      "000041      Atelectasis,Effusion,Pleural_Thickening,                  No Finding,                   \n",
      "000042      Cardiomegaly,                                             No Finding,                   \n",
      "000043      Cardiomegaly,                                             No Finding,                   \n",
      "000044      Consolidation,Edema,Infiltration,                         Nodule,                       \n",
      "000045                                                                No Finding,                   \n",
      "000046                                                                Atelectasis,                  \n",
      "000047      Atelectasis,Mass,Nodule,Pleural_Thickening,               Effusion,Infiltration,Nodule,Pleural_Thickening,\n",
      "000048      Cardiomegaly,Mass,                                        No Finding,                   \n",
      "000049      Atelectasis,Consolidation,Infiltration,Pneumonia,         Infiltration,                 \n",
      "000050      No Finding,                                               No Finding,                   \n",
      "000051      No Finding,                                               Atelectasis,                  \n",
      "000052      Fibrosis,                                                 No Finding,                   \n",
      "000053      No Finding,                                               No Finding,                   \n",
      "000054      No Finding,                                               No Finding,                   \n",
      "000055      No Finding,                                               No Finding,                   \n",
      "000056      No Finding,                                               No Finding,                   \n",
      "000057      Effusion,Infiltration,                                    Effusion,Nodule,Pneumothorax, \n",
      "000058      Atelectasis,                                              Atelectasis,                  \n",
      "000059      Atelectasis,Consolidation,Effusion,                       Atelectasis,Infiltration,     \n",
      "000060      Consolidation,Effusion,Mass,                              No Finding,                   \n",
      "000061      Edema,                                                    Atelectasis,                  \n",
      "000062      Cardiomegaly,                                             No Finding,                   \n",
      "000063      No Finding,                                               No Finding,                   \n",
      "000064      No Finding,                                               No Finding,                   \n",
      "000065      Atelectasis,Consolidation,Edema,Effusion,                 Atelectasis,Pneumothorax,     \n",
      "000066      Effusion,Infiltration,                                    No Finding,                   \n",
      "000067      Edema,Infiltration,                                       Edema,                        \n",
      "000068      No Finding,                                               No Finding,                   \n",
      "000069      Cardiomegaly,Edema,                                       Edema,                        \n",
      "000070      No Finding,                                               No Finding,                   \n",
      "000071      No Finding,                                               No Finding,                   \n",
      "000072      Effusion,Infiltration,Pneumothorax,                       Emphysema,Nodule,             \n",
      "000073      No Finding,                                               No Finding,                   \n",
      "000074      Atelectasis,Consolidation,Fibrosis,                       Atelectasis,                  \n",
      "000075      No Finding,                                               No Finding,                   \n",
      "000076      Atelectasis,Effusion,Pneumothorax,                        No Finding,                   \n",
      "000077      Atelectasis,Effusion,Pleural_Thickening,                  No Finding,                   \n",
      "000078      Pneumothorax,                                             No Finding,                   \n",
      "000079      Pneumothorax,                                             No Finding,                   \n",
      "000080      Atelectasis,Cardiomegaly,Consolidation,Effusion,          Atelectasis,                  \n",
      "000081      Pneumothorax,                                             Cardiomegaly,                 \n",
      "000082      Edema,Infiltration,Pneumothorax,                          No Finding,                   \n",
      "000083      Edema,                                                    Infiltration,                 \n",
      "000084      Atelectasis,Consolidation,Effusion,Pneumothorax,          Pneumothorax,                 \n",
      "000085      Mass,                                                     Nodule,                       \n",
      "000086      Mass,                                                     Mass,                         \n",
      "000087      Atelectasis,Consolidation,Effusion,Pneumothorax,          No Finding,                   \n",
      "000088      Atelectasis,                                              Atelectasis,Consolidation,    \n",
      "000089      Atelectasis,Hernia,                                       Atelectasis,                  \n",
      "000090      No Finding,                                               No Finding,                   \n",
      "000091      Edema,Effusion,                                           Mass,                         \n",
      "000092      No Finding,                                               No Finding,                   \n",
      "000093      No Finding,                                               No Finding,                   \n",
      "000094      Atelectasis,Effusion,Pleural_Thickening,Pneumothorax,     Pleural_Thickening,           \n",
      "000095      Atelectasis,Consolidation,Effusion,                       Consolidation,Infiltration,   \n",
      "000096      No Finding,                                               Infiltration,                 \n",
      "000097      Atelectasis,Cardiomegaly,Edema,                           No Finding,                   \n",
      "000098      No Finding,                                               No Finding,                   \n",
      "000099      Atelectasis,Consolidation,Effusion,                       Atelectasis,Effusion,Infiltration,\n",
      "000100      Atelectasis,                                              Atelectasis,                  \n"
     ]
    }
   ],
   "source": [
    "#Comparison between radiologist and source labels.\n",
    "\n",
    "dash = '-' * 120\n",
    "print(\"id{:<10}  Radiologist{:<57} Source{:<20}\"\n",
    "          .format(\"\",\n",
    "                  \"\",\n",
    "                  \"\",\n",
    "                 \"\"))\n",
    "print(dash + \"\\n\")\n",
    "\n",
    "for radiologist_item in radiologist_csvtokens:\n",
    "    \n",
    "    radiologist_labels = \"\"\n",
    "    for x in radiologist_item['labels']:\n",
    "        radiologist_labels += x +\",\"\n",
    "    \n",
    "    labels = filename_to_source_labels[radiologist_item['filename'][0]][0]\n",
    "    source_labels = \"\"\n",
    "    for x in labels:\n",
    "        source_labels += x +\",\"\n",
    "    \n",
    "    print(\"{:<10s}  {:<57s} {:<30s}\"\n",
    "          .format(radiologist_item['id'],\n",
    "                  radiologist_labels,\n",
    "                  source_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_jaccard():\n",
    "    intersection_count = 0\n",
    "    union_count = 0\n",
    "    for radiologist_item in radiologist_csvtokens:\n",
    "        source_labels = filename_to_source_labels[radiologist_item['filename'][0]][0]\n",
    "        radiologist_labels = radiologist_item['labels']\n",
    "        intersection = set(source_labels) & set(radiologist_labels)\n",
    "        union = set(source_labels) | set(radiologist_labels)\n",
    "        intersection_count += len(intersection)\n",
    "        union_count += len(union)\n",
    "    return intersection_count/union_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23770491803278687"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_jaccard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save golden images\n",
    "\n",
    "images = []\n",
    "\n",
    "for doc in radiologist_csvtokens:\n",
    "    filename = doc['filename'][0]\n",
    "    file_path = os.path.join(ORIGINAL_IMAGES_DIR, filename)\n",
    "    img = mpimg.imread(file_path)\n",
    "    save_path = os.path.join(GOLDEN_IMAGES_DIR, filename)\n",
    "    plt.imsave(save_path, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((15,15), dtype=int)\n",
    "for doc in golden_documents:\n",
    "    \n",
    "    radiologist_labels = filename_to_radiologist_labels[doc['filename']][0]\n",
    "    source_labels = filename_to_source_labels[doc['filename']][0]\n",
    "    for r_label in radiologist_labels:\n",
    "        i = ids_by_label_key1[r_label]\n",
    "        if(r_label in source_labels):\n",
    "            confusion_matrix[i][i] += 1 \n",
    "        else:\n",
    "            for s_label in source_labels:\n",
    "                j = ids_by_label_key1[s_label]\n",
    "                confusion_matrix[i][j] += 1 \n",
    "    \n",
    "    for s_label in source_labels:\n",
    "        j = ids_by_label_key1[s_label]\n",
    "        if(s_label in radiologist_labels):\n",
    "            continue \n",
    "        else:\n",
    "            for r_label in radiologist_labels:\n",
    "                i = ids_by_label_key1[r_label]\n",
    "                confusion_matrix[i][j] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     At   Ca   Co   Ed   Ef   Em   Fi   He   In   Ma   No   No   Pl   Pn   Pn   \n",
      "\n",
      "At   10   0    2    0    4    5    2    1    8    1    1    18   5    0    2    \n",
      "\n",
      "Ca   3    0    2    1    0    0    0    0    2    0    0    12   0    0    0    \n",
      "\n",
      "Co   5    0    1    0    3    4    0    0    8    0    2    8    1    0    4    \n",
      "\n",
      "Ed   3    0    0    2    1    0    0    0    2    2    2    8    0    0    2    \n",
      "\n",
      "Ef   4    0    1    0    5    10   2    1    5    2    3    18   3    0    5    \n",
      "\n",
      "Em   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    \n",
      "\n",
      "Fi   1    0    0    2    1    0    0    0    0    0    0    4    0    0    0    \n",
      "\n",
      "He   1    0    0    0    0    0    1    1    0    0    0    2    0    0    0    \n",
      "\n",
      "In   0    0    1    1    2    2    0    0    6    0    6    4    1    0    2    \n",
      "\n",
      "Ma   0    0    0    0    2    0    0    0    2    2    3    6    2    0    0    \n",
      "\n",
      "No   0    0    0    0    1    0    0    0    1    0    1    0    0    0    0    \n",
      "\n",
      "No   2    0    0    0    0    0    2    0    4    0    4    24   0    0    0    \n",
      "\n",
      "Pl   1    0    0    0    1    7    2    1    1    0    0    4    3    0    1    \n",
      "\n",
      "Pn   0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    \n",
      "\n",
      "Pn   1    2    0    0    0    7    0    0    0    0    2    8    1    0    2    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<4s} \".format(\"\"), end=\"\")\n",
    "for label_name in LABEL_KEYS1:\n",
    "    print(\"{:<4s} \".format(label_name[:2]), end=\"\")\n",
    "print(\"\\n\")   \n",
    "for i,row in enumerate(confusion_matrix):\n",
    "    print(\"{:<4s} \".format(LABEL_KEYS1[i][:2]), end=\"\")\n",
    "    for j in row:\n",
    "        print(\"{:<4d} \".format(j), end=\"\")\n",
    "    print(\"\\n\")    \n",
    "    \n",
    "    LABEL_KEYS1 = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"No Finding\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(item1, item2):\n",
    "    \n",
    "    intersection = set(item1) & set(item2)\n",
    "    union = set(item1) | set(item2)\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for doc in golden_documents:\n",
    "    radiologist_labels = filename_to_radiologist_labels[doc['filename']][0]\n",
    "    source_labels = filename_to_source_labels[doc['filename']][0]\n",
    "    j = jaccard(radiologist_labels, source_labels)\n",
    "    y.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for doc in golden_documents:\n",
    "    cat = doc['mu']+doc['labels']\n",
    "    X.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = []\n",
    "for doc in val_documents:\n",
    "    val.append( doc['mu'] + doc['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "y_rbf = svr_rbf.fit(X, y).predict(val)\n",
    "y_lin = svr_lin.fit(X, y).predict(val)\n",
    "y_poly = svr_poly.fit(X, y).predict(val)\n",
    "\n",
    "ranking_rbf = sorted(y_rbf)\n",
    "ranking_lin = sorted(y_lin)\n",
    "ranking_poly = sorted(y_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "#generate a sprite image consisting of all the images\n",
    "def create_sprite_image(documents, directory):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    \n",
    "    images = []\n",
    "    for doc in documents:\n",
    "        path = os.path.join(ORIGINAL_IMAGES_DIR, doc['filename'])\n",
    "        img = mpimg.imread(path)\n",
    "        if len(np.shape(img)) == 3:\n",
    "            img = rgb2gray(img)\n",
    "        \n",
    "        images.append(img)\n",
    "\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "                \n",
    "    plt.imsave(directory, spriteimage, cmap='gray')\n",
    "    plt.imshow(spriteimage,cmap='gray')\n",
    "    \n",
    "    return spriteimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a metadata consisting of index and label of our embedding vectors\n",
    "#The Index is simply the index in our embedding matrix. The label is a string of a patient's diseases.\n",
    "def create_metadata(documents, directory):\n",
    "    \n",
    "    match = 0\n",
    "    radiologist_labels = filename_to_radiologist_labels[doc['filename']][0]\n",
    "    source_labels = filename_to_source_labels[doc['filename']][0]\n",
    "    if (set(radiologist_labels) == set(source_labels)):\n",
    "        match = 1\n",
    "    \n",
    "    \n",
    "    with open(directory,'w') as f:\n",
    "        f.write(\"Index\\tLabels\\tFirst_label\\n\")\n",
    "        for index,doc in enumerate(documents):\n",
    "            f.write(\"%d\\t%d\\t%s\\t%s\\n\" % (index, match, source_labels, radiologist_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprite_image = create_sprite_image(documents, SPRITE_DIR)\n",
    "metadata = create_metadata(documents, META_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed embedding variables into feed into the visualizer\n",
    "mu_embedding = []\n",
    "sigma_embedding = []\n",
    "embeddings = []\n",
    "embedding_names = []\n",
    "\n",
    "for doc in documents:\n",
    "        mu_embedding.append(doc['mu'].tolist())\n",
    "embeddings.append(mu_embedding)\n",
    "embedding_names.append('mu')\n",
    "\n",
    "for doc in documents:\n",
    "        sigma_embedding.append(doc['sigma'].tolist())\n",
    "embeddings.append(sigma_embedding)\n",
    "embedding_names.append('sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify what variable you want to project, what the metadata path is (the names and classes),\n",
    "#and where you save the sprites\n",
    "summary_writer = tf.summary.FileWriter(VIS_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "for i,e in enumerate(embeddings):\n",
    "    \n",
    "    embedding_var = tf.Variable(e, name=embedding_names[i])\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "\n",
    "    # Specify where you find the metadata\n",
    "    embedding.metadata_path = 'metadata.tsv' #'metadata.tsv'\n",
    "\n",
    "    # Specify where you find the sprite (we will create this later)\n",
    "    embedding.sprite.image_path = 'sprite.png' #'sprite.png'\n",
    "    embedding.sprite.single_image_dim.extend([256,256])\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard loads the saved variable from the saved graph. \n",
    "#Initialise a session and variables, and save them in your logging directory.\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(VIS_DIR, \"model1.ckpt\"), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
