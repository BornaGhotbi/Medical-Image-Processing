{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Built using guidance from https://arxiv.org/pdf/1512.09300.pdf\n",
    "\n",
    "Features:\n",
    "  * Uses ELU activations\n",
    "  * Deconvolution uses upscaling unpool layer before affine operator, rather than spacing with zeros\n",
    "  * Batch normalization after each transformation\n",
    "  * Dropout layer after activation\n",
    "  * abs-sum image loss rather than cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Best result so far is 10 epochs of the first training batch, with the prior and the prediction weighted equally.\n",
    "\n",
    "Running another 10 epochs doesn't hurt the similarity results, but it does make the reconstructions worse.\n",
    "\n",
    "Not quite as good after 10 epochs with regularization=0.1 (down-weighted prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow version 1.8.0-dev20180330\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "print(\"running TensorFlow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control memory usage\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report OOM details\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_256_pattern = re.compile('^train_(?P<block_id>[0-9]{3})_256x256\\.tfrecords')\n",
    "validate_256_pattern = re.compile('^validate_(?P<block_id>[0-9]{3})_256x256\\.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFRECORDS_DIR = os.path.join(DATA_ROOT, 'tfrecords_alt')\n",
    "\n",
    "ALL_TFRECORDS = os.listdir(TFRECORDS_DIR)\n",
    "\n",
    "def get_sorted_records(pattern, directory):\n",
    "     return [ \\\n",
    "         os.path.join(directory, _file) \\\n",
    "         for _file in \\\n",
    "         sorted([_m[0] for _m in \\\n",
    "             [pattern.match(_f) for _f in os.listdir(directory)] if _m]) \\\n",
    "     ]\n",
    "\n",
    "TRAIN_TFRECORDS = get_sorted_records(train_256_pattern, TFRECORDS_DIR)\n",
    "VALIDATE_TFRECORDS = get_sorted_records(validate_256_pattern, TFRECORDS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../../data/tfrecords_alt/train_003_256x256.tfrecords'],\n",
       " ['../../data/tfrecords_alt/validate_003_256x256.tfrecords'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_TFRECORDS, VALIDATE_TFRECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = 'vae/vae_08'\n",
    "SUMMARY_DIR = os.path.join(DATA_ROOT, 'logs', RUN_NAME)\n",
    "MODEL_DIR = os.path.join(DATA_ROOT, 'models', RUN_NAME)\n",
    "MODEL_GRAPH = os.path.join(MODEL_DIR, 'vae.meta')\n",
    "MODEL_PREFIX = os.path.join(MODEL_DIR, 'vae')\n",
    "VIS_DIR = os.path.join(SUMMARY_DIR,'vis')\n",
    "SPRITE_DIR = os.path.join(VIS_DIR, 'sprite.png')\n",
    "META_DIR =  os.path.join(VIS_DIR, 'metadata.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(SUMMARY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode(serialized_example):\n",
    "    '''Parses an image and label from the given `serialized_example`\n",
    "    '''\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'filename': tf.FixedLenFeature([], tf.string),\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'view': tf.FixedLenFeature([], tf.string),\n",
    "            'gender': tf.FixedLenFeature([], tf.string),\n",
    "            'age': tf.FixedLenFeature([], tf.int64),\n",
    "            'labels': tf.FixedLenSequenceFeature( [], dtype=tf.int64, default_value=-1,allow_missing=True)\n",
    "            })\n",
    "       \n",
    "\n",
    "    # Convert from a scalar string tensor\n",
    "    filename = tf.cast(features['filename'], tf.string)\n",
    "    image = tf.decode_raw(features['image'], tf.float32)\n",
    "    view = tf.cast(features['view'], tf.string)\n",
    "    gender = tf.cast(features['gender'], tf.string)\n",
    "    age = tf.cast(features['age'], tf.int32)\n",
    "    labels = tf.cast(features['labels'], tf.int32)\n",
    "    \n",
    "    return filename, image, view, gender, age, labels\n",
    "\n",
    "\n",
    "def _augment(filename, image, view, gender, age, labels):\n",
    "    '''Placeholder for data augmentation\n",
    "    '''\n",
    "    image = tf.reshape(image, [256, 256, 1])\n",
    "    return filename, image, view, gender, age, labels\n",
    "\n",
    "\n",
    "def _normalize(filename, image, view, gender, age, labels):\n",
    "    '''Convert `image` from [0, 255] -> [-0.5, 0.5] floats\n",
    "    '''\n",
    "    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "    return filename, image, view, gender, age, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(filenames, batch_size, num_epochs):\n",
    "    ''' Reads input data num_epochs times or forever if num_epochs is None\n",
    "        returns dataset, iterator pair\n",
    "    '''\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        # TFRecordDataset opens a binary file and reads one record at a time.\n",
    "        # `filename` could also be a list of filenames, which will be read in order.\n",
    "        dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "        # The map transformation takes a function and applies it to every element\n",
    "        # of the dataset.\n",
    "        dataset = dataset.map(_decode)\n",
    "        dataset = dataset.map(_augment)\n",
    "        dataset = dataset.map(_normalize)\n",
    "\n",
    "        # The shuffle transformation uses a finite-sized buffer to shuffle elements\n",
    "        # in memory. The parameter is the number of elements in the buffer. For\n",
    "        # completely uniform shuffling, set the parameter to be the same as the\n",
    "        # number of elements in the dataset.\n",
    "        dataset = dataset.shuffle(1000 + 3 * batch_size)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return dataset, iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "DROPOUT = 0.7\n",
    "REGULARIZATION = 0.1\n",
    "\n",
    "DISPLAY_EVERY = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summary(x, name):\n",
    "    with tf.variable_scope(name):\n",
    "        mean = tf.reduce_mean(x)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(x))\n",
    "        tf.summary.scalar('min', tf.reduce_min(x))\n",
    "        tf.summary.histogram('histogram', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpool operation doesn't yet exist in TF\n",
    "\n",
    "def unpool_op(x, stride, name='unpool'):\n",
    "\n",
    "    with tf.name_scope(name) as scope:\n",
    "\n",
    "        if stride==1:\n",
    "            return x\n",
    "\n",
    "        shape = x.get_shape().as_list()\n",
    "        dim = len(shape[1:-1])\n",
    "        out = (tf.reshape(x, [-1] + shape[-dim:]))\n",
    "        for i in range(dim, 0, -1):\n",
    "            out = tf.concat([out]*stride, i)\n",
    "        out_size = [-1] + [s * stride for s in shape[1:-1]] + [shape[-1]]\n",
    "        out = tf.reshape(out, out_size, name=scope)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_layer(x, dims, stride, train, bias=None, name='conv', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        if bias is None:\n",
    "             conv = tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1], padding='SAME', name='conv')\n",
    "        else:\n",
    "             conv = tf.nn.bias_add(tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1],\n",
    "                        padding='SAME'), biases, name='conv')\n",
    "        normalized = tf.layers.batch_normalization(conv, axis=3, training=train,\n",
    "                    name='spatial_batch_norm')        \n",
    "        activations = activation(normalized, name='activation')\n",
    "        activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', normalized)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolution_layer(x, dims, stride, train, bias=None, name='deconv', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        unpool = unpool_op(x, stride, name='unpool')\n",
    "        if bias is None:\n",
    "            deconv = tf.nn.conv2d(unpool, weights, strides=[1, 1, 1, 1], padding='SAME', name='deconv')\n",
    "        else:\n",
    "            deconv = tf.nn.bias_add(tf.nn.conv2d(unpool, weights, strides=[1, 1, 1, 1],\n",
    "                        padding='SAME'), biases, name='deconv')\n",
    "        normalized = tf.layers.batch_normalization(deconv, axis=3, training=train,\n",
    "                    name='spatial_batch_norm')        \n",
    "        activations = activation(deconv, name='activation')\n",
    "        activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', deconv)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(x, dims, train, bias=None, name='fc', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        if bias is None:\n",
    "            dense = tf.matmul(x, weights, name='dense')\n",
    "        else:\n",
    "            dense = tf.nn.bias_add(tf.matmul(x, weights), biases, name='dense')\n",
    "\n",
    "        normalized = tf.layers.batch_normalization(dense, axis=1, training=train,\n",
    "                    name='batch_norm')\n",
    "        activations = activation(normalized, name='activation')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', normalized)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_sample(mean, stddev, name):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # mean is unconstrained; stddev must be strictly positive\n",
    "        stddev = 1e-6 + tf.nn.softplus(stddev)\n",
    "\n",
    "        # actually sample\n",
    "        z = mean + stddev * tf.random_normal(tf.shape(mean), 0, 1, dtype=tf.float32)\n",
    "\n",
    "        # Variable summaries\n",
    "        tf.summary.histogram('mean', mean)\n",
    "        tf.summary.histogram('stddev', stddev)\n",
    "        tf.summary.histogram('z', z)\n",
    "\n",
    "        return mean, stddev, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, xhat, mu, sigma):\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        # Structure\n",
    "        pred = tf.losses.absolute_difference(x, xhat,\n",
    "                reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "        # offsetx = x + 0.5\n",
    "        # pred = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        #         labels=offsetx, logits=xhat))\n",
    "\n",
    "        KLdiv = 0.5 * tf.reduce_mean(tf.square(mu) + \\\n",
    "                    tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1)\n",
    "\n",
    "        loss = tf.add(REGULARIZATION * KLdiv, pred)\n",
    "\n",
    "        # Summaries\n",
    "        tf.summary.scalar('prediction', pred)\n",
    "        tf.summary.scalar('prior', KLdiv)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    return loss, pred, KLdiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(img, train):\n",
    "\n",
    "    with tf.variable_scope('encoder'):\n",
    "\n",
    "        # convolution\n",
    "        conv1 = convolution_layer(img, [5, 5, 1, 64], 2, train, name='conv1')\n",
    "        conv2 = convolution_layer(conv1, [5, 5, 64, 128], 2, train, name='conv2')\n",
    "        conv3 = convolution_layer(conv2, [5, 5, 128, 256], 2, train, name='conv3')\n",
    "\n",
    "        # transition\n",
    "        conv3 = tf.reshape(conv3, [-1, 32*32*256], name='reshape1')\n",
    "\n",
    "        # dense output\n",
    "        fc1 = dense_layer(conv3, [32*32*256, 256], train,\n",
    "                activation=tf.identity, name='fc1')\n",
    "\n",
    "        # sample\n",
    "        mu, sigma, z = gaussian_sample(fc1[:, :128], fc1[:, 128:], name='output')\n",
    "\n",
    "    return mu, sigma, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, train):\n",
    "\n",
    "    with tf.variable_scope('decoder'):\n",
    "\n",
    "        # dense input\n",
    "        fc1 = dense_layer(z, [128, 32*32*256], train, name='fc1')\n",
    "\n",
    "        # transition\n",
    "        fc1 = tf.reshape(fc1, [-1, 32, 32, 256], name='reshape1')\n",
    "\n",
    "        # deconvolution\n",
    "        deconv1 = deconvolution_layer(fc1, [5, 5, 256, 128], 2, train,\n",
    "                            name='deconv1')\n",
    "        deconv2 = deconvolution_layer(deconv1, [5, 5, 128, 64], 2, train, \n",
    "                            name='deconv2')\n",
    "        deconv3 = deconvolution_layer(deconv2, [5, 5, 64, 32], 2, train,\n",
    "                            name='deconv3')\n",
    "        logits = deconvolution_layer(deconv3, [5, 5, 32, 1], 1, train,\n",
    "                            activation=tf.identity, name='logits')\n",
    "\n",
    "        # put into image range for display\n",
    "        with tf.name_scope('range'):\n",
    "            xhat = 0.5 * tf.nn.tanh(logits)\n",
    "\n",
    "    return xhat, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    format=\"%(asctime)s [train/initialize] %(levelname)-8s %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "NOW_STR = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "RUN_DESC = \"cross-entropy loss, 256x256 images, no bias\"\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07T17:00:49+0000 [train/initialize] INFO     initializing run: vae/vae_08\n",
      "2018-06-07T17:00:56+0000 [train/initialize] INFO       step      loss      recon     reg\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=42, seed2=110, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](encoder/conv1/dropout/cond/dropout/Shape-0-0-VecPermuteNCHWToNHWC-LayoutOptimizer/_11)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\t [[Node: decoder/fc1/batch_norm/cond_3/Merge/_84 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_805_decoder/fc1/batch_norm/cond_3/Merge\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\nCaused by op 'encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-7a16705582b6>\", line 127, in <module>\n    main()\n  File \"<ipython-input-30-7a16705582b6>\", line 122, in main\n    initialize()\n  File \"<ipython-input-30-7a16705582b6>\", line 48, in initialize\n    mu, sigma, z = encoder(images, train)\n  File \"<ipython-input-27-6db4fb288e6f>\", line 6, in encoder\n    conv1 = convolution_layer(img, [5, 5, 1, 64], 2, train, name='conv1')\n  File \"<ipython-input-22-7cac07ac1ea6>\", line 22, in convolution_layer\n    activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 351, in dropout\n    return layer.apply(inputs, training=training)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 827, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 716, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 306, in call\n    lambda: array_ops.identity(inputs))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/smart_cond.py\", line 60, in smart_cond\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2053, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1903, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 303, in dropped_inputs\n    seed=self.seed)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2316, in dropout\n    noise_shape, seed=seed, dtype=x.dtype)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1674, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=42, seed2=110, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](encoder/conv1/dropout/cond/dropout/Shape-0-0-VecPermuteNCHWToNHWC-LayoutOptimizer/_11)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\t [[Node: decoder/fc1/batch_norm/cond_3/Merge/_84 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_805_decoder/fc1/batch_norm/cond_3/Merge\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1315\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=42, seed2=110, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](encoder/conv1/dropout/cond/dropout/Shape-0-0-VecPermuteNCHWToNHWC-LayoutOptimizer/_11)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\t [[Node: decoder/fc1/batch_norm/cond_3/Merge/_84 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_805_decoder/fc1/batch_norm/cond_3/Merge\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7a16705582b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-7a16705582b6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'initialize training graph'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-7a16705582b6>\u001b[0m in \u001b[0;36minitialize\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m             _, step = session.run([optimizer, global_step],\n\u001b[1;32m    103\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mdata_handle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     options = run_options)\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             loss_, recon_, reg_, summary =                 session.run([loss, recon, reg, merged],\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 908\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    909\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1143\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1144\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1324\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1325\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=42, seed2=110, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](encoder/conv1/dropout/cond/dropout/Shape-0-0-VecPermuteNCHWToNHWC-LayoutOptimizer/_11)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\t [[Node: decoder/fc1/batch_norm/cond_3/Merge/_84 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_805_decoder/fc1/batch_norm/cond_3/Merge\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\nCaused by op 'encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-30-7a16705582b6>\", line 127, in <module>\n    main()\n  File \"<ipython-input-30-7a16705582b6>\", line 122, in main\n    initialize()\n  File \"<ipython-input-30-7a16705582b6>\", line 48, in initialize\n    mu, sigma, z = encoder(images, train)\n  File \"<ipython-input-27-6db4fb288e6f>\", line 6, in encoder\n    conv1 = convolution_layer(img, [5, 5, 1, 64], 2, train, name='conv1')\n  File \"<ipython-input-22-7cac07ac1ea6>\", line 22, in convolution_layer\n    activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 351, in dropout\n    return layer.apply(inputs, training=training)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 827, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 716, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 306, in call\n    lambda: array_ops.identity(inputs))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/smart_cond.py\", line 60, in smart_cond\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2053, in cond\n    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 1903, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 303, in dropped_inputs\n    seed=self.seed)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2316, in dropout\n    noise_shape, seed=seed, dtype=x.dtype)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\", line 242, in random_uniform\n    rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed1, seed2=seed2)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\", line 672, in random_uniform\n    name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3327, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1674, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: encoder/conv1/dropout/cond/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=42, seed2=110, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](encoder/conv1/dropout/cond/dropout/Shape-0-0-VecPermuteNCHWToNHWC-LayoutOptimizer/_11)]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n\t [[Node: decoder/fc1/batch_norm/cond_3/Merge/_84 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_805_decoder/fc1/batch_norm/cond_3/Merge\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCurrent usage from device: /job:localhost/replica:0/task:0/device:GPU:0, allocator: GPU_0_bfc\n  128.00MiB from encoder/conv1/spatial_batch_norm/cond/FusedBatchNorm\n  128.00MiB from encoder/conv1/conv\n  128.00MiB from encoder/conv1/dropout/cond/dropout/div\n  Remaining 1 nodes with 256B\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def initialize():\n",
    "\n",
    "    logging.info(\"initializing run: {}\".format(RUN_NAME))\n",
    "\n",
    "    # write a note regarding this run\n",
    "    os.makedirs(SUMMARY_DIR, exist_ok=True)\n",
    "    with open(os.path.join(SUMMARY_DIR, \"description.txt\"), 'w') as fh:\n",
    "        fh.write(NOW_STR+\" \"+RUN_DESC)\n",
    "\n",
    "    # Control memory usage\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    # Report OOM details\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "    # Build graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "\n",
    "        # Repeatable results\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "        # Get Data\n",
    "        train_dataset, train_iterator = inputs(filenames=TRAIN_TFRECORDS,\n",
    "                batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "        # Data placeholder\n",
    "        data_handle = tf.placeholder(tf.string, shape=[])\n",
    "        iterator = tf.data.Iterator.from_string_handle(\n",
    "            data_handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "        \n",
    "       \n",
    "\n",
    "        filename, images, view, gender, age, labels = iterator.get_next()\n",
    "\n",
    "        # Train/validate flag\n",
    "        train = tf.placeholder(tf.bool)\n",
    "\n",
    "        # Global counter\n",
    "        global_step = tf.train.get_or_create_global_step(graph)\n",
    "\n",
    "        # Dropout\n",
    "        dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "        # Autoencoder\n",
    "        mu, sigma, z = encoder(images, train)\n",
    "        xhat, logits = decoder(z, train)\n",
    "        loss, recon, reg = evaluate(images, xhat, mu, sigma)\n",
    "\n",
    "        # Training branch - control dependencies so batchnorm params are updated\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\\\n",
    "                .minimize(loss, global_step=global_step, name='optimizer')\n",
    "\n",
    "        # Log output for Tensorboard\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_summary_logger = tf.summary.FileWriter(SUMMARY_DIR+'/train',\n",
    "                        graph=graph, flush_secs=30)\n",
    "\n",
    "        # Initializer\n",
    "        init_variables = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        # Save state\n",
    "        tf.add_to_collection('optimizer', optimizer)\n",
    "\n",
    "        tf.add_to_collection('filename', filename)\n",
    "        tf.add_to_collection('images', images)\n",
    "        tf.add_to_collection('view', view)\n",
    "\n",
    "        tf.add_to_collection('gender', gender)\n",
    "        tf.add_to_collection('age', age)\n",
    "        tf.add_to_collection('labels', labels)\n",
    "        \n",
    "        tf.add_to_collection('mu', mu)\n",
    "        \n",
    "        tf.add_to_collection('sigma', sigma)\n",
    "        tf.add_to_collection('xhat', xhat)\n",
    "\n",
    "        tf.add_to_collection('loss', loss)\n",
    "        tf.add_to_collection('recon', recon)\n",
    "        tf.add_to_collection('reg', reg)\n",
    "\n",
    "        tf.add_to_collection('data_handle', data_handle)\n",
    "        tf.add_to_collection('train', train)\n",
    "\n",
    "        tf.add_to_collection('merged', merged)\n",
    "\n",
    "        writer = tf.train.Saver()\n",
    "\n",
    "        # Run one step: this initializes the graph and saves our starting statistics\n",
    "        with tf.Session(config=config) as session:\n",
    "\n",
    "            session.run(init_variables)\n",
    "\n",
    "            train_handle = session.run(train_iterator.string_handle())\n",
    "\n",
    "            # Output header\n",
    "            logging.info(\"  step      loss      recon     reg\")\n",
    "\n",
    "            _, step = session.run([optimizer, global_step],\n",
    "                    feed_dict = { data_handle: train_handle, train: 1 },\n",
    "                    options = run_options)\n",
    "\n",
    "            loss_, recon_, reg_, summary = \\\n",
    "                session.run([loss, recon, reg, merged],\n",
    "                           feed_dict = { data_handle: train_handle, train: 0 })\n",
    "            train_summary_logger.add_summary(summary, step)\n",
    "\n",
    "            logging.info(\"{: 6d} {:9.3g} {:9.3g} {:9.3g}\".format(step, loss_, recon_, reg_))\n",
    "\n",
    "            # Save graph\n",
    "            logging.info(\"saving graph\")\n",
    "            writer.save(session, MODEL_PREFIX, global_step=step, write_meta_graph=False)\n",
    "            writer.export_meta_graph(MODEL_GRAPH)\n",
    "            \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='initialize training graph')\n",
    "    initialize()\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/vae/vae_08/vae-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-06T19:51:23+0000 [train/initialize] INFO     Restoring parameters from ../../data/models/vae/vae_08/vae-0\n",
      "2018-06-06T19:51:24+0000 [train/initialize] INFO       step      loss      recon     reg\n",
      "2018-06-06T19:52:07+0000 [train/initialize] INFO        100     0.362      0.34     0.217\n",
      "2018-06-06T19:53:02+0000 [train/initialize] INFO        200     0.375     0.345     0.295\n",
      "2018-06-06T19:53:58+0000 [train/initialize] INFO        300     0.355     0.326     0.289\n",
      "2018-06-06T19:54:53+0000 [train/initialize] INFO        400     0.364     0.327     0.368\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "    # Repeatable results\n",
    "    tf.set_random_seed(0)\n",
    "\n",
    "    # Get Data\n",
    "    _, train_iterator = inputs(filenames=TRAIN_TFRECORDS, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "        \n",
    "    # Log output for Tensorboard\n",
    "    train_summary_logger = tf.summary.FileWriter(SUMMARY_DIR+'/train', flush_secs=30)\n",
    "\n",
    "    # Run\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        # restore\n",
    "        reader = tf.train.import_meta_graph(MODEL_GRAPH)\n",
    "        reader.restore(session, tf.train.latest_checkpoint(MODEL_DIR))\n",
    "\n",
    "        # must be called after reader so that the graph is populated\n",
    "        writer = tf.train.Saver()\n",
    "\n",
    "        # get references to graph endpoints\n",
    "        global_step = tf.train.get_global_step(graph)\n",
    "\n",
    "        optimizer = tf.get_collection('optimizer')[0]\n",
    "        loss = tf.get_collection('loss')[0]\n",
    "        recon = tf.get_collection('recon')[0]\n",
    "        reg = tf.get_collection('reg')[0]\n",
    "\n",
    "        data_handle = tf.get_collection('data_handle')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "\n",
    "        merged = tf.get_collection('merged')[0]\n",
    "\n",
    "        train_handle = session.run(train_iterator.string_handle())\n",
    "\n",
    "        # Output header\n",
    "        logging.info(\"  step      loss      recon     reg\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                _, step = session.run([optimizer, global_step], \n",
    "                            feed_dict = { data_handle: train_handle, train: 1 })\n",
    "\n",
    "                if not step%DISPLAY_EVERY:\n",
    "\n",
    "                    loss_, recon_, reg_, summary = session.run([loss, recon, reg, merged],\n",
    "                            feed_dict = { data_handle: train_handle, train: 0 })\n",
    "                    train_summary_logger.add_summary(summary, step)\n",
    "\n",
    "                    logging.info(\"{: 6d} {:9.3g} {:9.3g} {:9.3g}\".format(\n",
    "                        step, loss_, recon_, reg_))\n",
    "\n",
    "                    writer.save(session, MODEL_PREFIX, global_step=step, write_meta_graph=False)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Try out the autoencoder by running it on some test set samples.\n",
    "\n",
    "For a collection of test images:\n",
    "\n",
    "1. Create (image, label, mu, sigma) tuples\n",
    "1. For a seed image, compute the 10 nearest images using (mu, sigma)\n",
    "1. View the nearby images and their labels, comparing them to the seed image\n",
    "\n",
    "If the VAE has worked as expected, we should find that the nearby images match the seed visually, and perhaps even match according to their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-148eab979470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Repeatable results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Store the documents\n",
    "documents = []\n",
    "\n",
    "def extend(docs, m, s, xh, f, i, v, a, g, l):\n",
    "    start_id = len(docs)\n",
    "    docs.extend([\n",
    "        {\n",
    "            'filename':f_.decode('ascii') ,\n",
    "            'id_': k + start_id,\n",
    "            'image': i_.reshape(256, 256)+0.5,\n",
    "            'view': v_.decode('ascii') ,\n",
    "            'age': a_,\n",
    "            'gender': g_.decode('ascii'),\n",
    "            'labels': l_,\n",
    "            'sigma': s_,\n",
    "            'mu': m_,\n",
    "            'xhat': y_.reshape(256, 256)+0.5\n",
    "        }\n",
    "        for k, (m_, s_, y_, f_, i_, v_, a_, g_, l_) in enumerate(zip(m, s, xh, f, i, v, a, g, l))\n",
    "    ])\n",
    "    return docs\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "    # Repeatable results\n",
    "    tf.set_random_seed(0)\n",
    "\n",
    "    # Get Data\n",
    "    _, validate_iterator = inputs(filenames=VALIDATE_TFRECORDS, batch_size=BATCH_SIZE, num_epochs=1)\n",
    "        \n",
    "    # Log output for Tensorboard\n",
    "    validate_summary_logger = tf.summary.FileWriter(SUMMARY_DIR+'/validate', flush_secs=30)\n",
    "\n",
    "    # Run\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        # restore\n",
    "        reader = tf.train.import_meta_graph(MODEL_GRAPH)\n",
    "        reader.restore(session, tf.train.latest_checkpoint(MODEL_DIR))\n",
    "        \n",
    "        # get references to graph endpoints\n",
    "        filename = tf.get_collection('filename')[0]\n",
    "        images = tf.get_collection('images')[0]\n",
    "        view = tf.get_collection('view')[0]\n",
    "        age = tf.get_collection('age')[0]\n",
    "        gender = tf.get_collection('gender')[0]\n",
    "        labels = tf.get_collection('labels')[0]\n",
    "\n",
    "        mu = tf.get_collection('mu')[0]\n",
    "        sigma = tf.get_collection('sigma')[0]\n",
    "        xhat = tf.get_collection('xhat')[0]\n",
    "        \n",
    "        merged = tf.get_collection('merged')[0]\n",
    "        \n",
    "        data_handle = tf.get_collection('data_handle')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "\n",
    "        validate_handle = session.run(validate_iterator.string_handle())\n",
    "        \n",
    "        step = 0\n",
    "        while True:\n",
    "            try:\n",
    "                mu_, sigma_, xhat_, filename_, images_, view_, age_, gender_, labels_, summary = \\\n",
    "                    session.run([mu, sigma, xhat, filename, images, view,  age, gender, labels, merged],\n",
    "                            feed_dict = { data_handle: validate_handle, train: 0 })\n",
    "                \n",
    "                documents = extend(documents, mu_, sigma_, xhat_, filename_, images_, view_, age_, gender_, labels_)\n",
    "                \n",
    "                step += 1\n",
    "                validate_summary_logger.add_summary(summary, step)                        \n",
    "                print(\"{}.\".format(step), end=\"\", flush=True)\n",
    "                    \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\".done\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(img,  cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "LABEL_KEYS = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Effusion\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Hernia\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"No Finding\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "]\n",
    "\n",
    "label_keys_by_id = LABEL_KEYS\n",
    "ids_by_label_key = OrderedDict([(k,v) for k, v in enumerate(label_keys_by_id)])\n",
    "  \n",
    "def getlabels(doc):\n",
    "    list = []\n",
    "    for index_value, index in enumerate(doc['labels']):\n",
    "        if(index == 1):\n",
    "            list.append(ids_by_label_key.get(index_value))\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "LABEL_KEYS_SHORT = [\n",
    "    \"Ats\",\n",
    "    \"Ca\",\n",
    "    \"Co\",\n",
    "    \"Ed\",\n",
    "    \"Ef\",\n",
    "    \"Em\",\n",
    "    \"Fi\",\n",
    "    \"He\",\n",
    "    \"In\",\n",
    "    \"Ma\",\n",
    "    \"No\",\n",
    "    \"No\",\n",
    "    \"Pl\",\n",
    "    \"Pn\",\n",
    "    \"Px\"\n",
    "]\n",
    "\n",
    "label_keys_by_id2 = LABEL_KEYS_SHORT\n",
    "ids_by_label_key2 = OrderedDict([(k,v) for k, v in enumerate(label_keys_by_id2)])\n",
    "\n",
    "def getlabels_short(doc):\n",
    "    list = []\n",
    "    for index_value, index in enumerate(doc['labels']):\n",
    "        if(index == 1):\n",
    "            list.append(ids_by_label_key2.get(index_value)[:2])\n",
    "            \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2118bc914304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id_'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'documents' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAFbCAYAAADGGAZpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAACNlJREFUeJzt2ktq88oCRtHSJUNw2r/mPxZ7EGknc6jbMuRliKMKJzus1StQo/gQYje0zTkHAAAU/e+/vgAAAHyXmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAEDWwz0Pn06nue/7D13l77tcLi9zzsfr2Z7H2HMte671fs8xbHqUd3Qte65lz7U++4beclfM7vs+zufz927F2Lbt6fXZnsfYcy17rvV+zzFsepR3dC17rmXPtT77ht7iNwMAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALK2OefXH9625zHG089d58/7N+d8vB7seZg917LnWm/2HMOmC3hH17LnWvZc68M39Ja7YhYAAH4TvxkAAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyHq45+HT6TT3ff+hq/x9l8vlZc75eD3b8xh7rmXPtd7vOYZNj/KOrmXPtey51mff0Fvuitl938f5fP7erRjbtj29PtvzGHuuZc+13u85hk2P8o6uZc+17LnWZ9/QW/xmAABAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgKxtzvn1h7fteYzx9HPX+fP+zTkfrwd7HmbPtey51ps9x7DpAt7Rtey5lj3X+vANveWumAUAgN/EbwYAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAssQsAABZYhYAgCwxCwBAlpgFACBLzAIAkCVmAQDIErMAAGSJWQAAsh7uefh0Os1933/oKn/f5XJ5mXM+Xs/2PMaea9lzrfd7jmHTo7yja9lzLXuu9dk39Ja7Ynbf93E+n793K8a2bU+vz/Y8xp5r2XOt93uOYdOjvKNr2XMte6712Tf0Fr8ZAACQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQtc05v/7wtj2PMZ5+7jp/3r855+P1YM/D7LmWPdd6s+cYNl3AO7qWPdey51ofvqG33BWzAADwm/jNAACALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAECWmAUAIEvMAgCQJWYBAMgSswAAZIlZAACyxCwAAFliFgCALDELAEDWwz0Pn06nue/7D13l77tcLi9zzsfr2Z7H2HMte671fs8xbHqUd3Qte65lz7U++4beclfM7vs+zufz927F2Lbt6fXZnsfYcy17rvV+zzFsepR3dC17rmXPtT77ht7iNwMAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAgS8wCAJAlZgEAyBKzAABkbXPOrz+8bc9jjKefu86f92/O+Xg92PMwe65lz7Xe7DmGTRfwjq5lz7XsudaHb+gtd8UsAAD8Jn4zAAAgS8wCAJAlZgEAyBKzAABkiVkAALLELAAAWWIWAIAsMQsAQJaYBQAg6/85lTLBXqyUqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(4, 8, figsize=(12, 6),\n",
    "                         subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.05)\n",
    "\n",
    "for ax, doc in zip(axes.flat, documents[32:64]):\n",
    "    ax.set_title(\"image {}\".format(doc['id_']))\n",
    "    ax.imshow(doc['image'])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 8, figsize=(12, 6),\n",
    "                         subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.05)\n",
    "\n",
    "for ax, doc in zip(axes.flat, documents[:32]):\n",
    "    ax.set_title(\"repro {}\".format(doc['id_']))\n",
    "    ax.imshow(doc['xhat'])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some example searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence-based distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(xbar, xsigma, ybar, ysigma):\n",
    "    ''' KL(x||y)\n",
    "    '''\n",
    "    xvar = xsigma**2\n",
    "    yvar = ysigma**2\n",
    "    \n",
    "    return 0.5*np.sum((xvar+(xbar-ybar)**2)/yvar - 1 + np.log(yvar/xvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_matrix = np.zeros((len(documents), len(documents)))\n",
    "\n",
    "for k, d1 in enumerate(documents):\n",
    "    for d2 in documents:\n",
    "        kl_matrix[d1['id_'], d2['id_']] = kl(d2['mu'], d2['sigma'], d1['mu'], d1['sigma'])\n",
    "    if not (k+1)%24:\n",
    "        print('.', end='', flush=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in documents[:4]:\n",
    "    def score(doc):\n",
    "        if doc['id_'] == seed['id_']:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return kl_matrix[seed['id_'], doc['id_']]\n",
    "\n",
    "    results = heapq.nsmallest(7, documents, key=score)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 8, figsize=(12, 2), subplot_kw={'xticks': [], 'yticks': []})\n",
    "    \n",
    "    axes[0].set_title(\"seed {}\".format(seed['id_']))\n",
    "    axes[0].imshow(seed['image'], cmap='gray')\n",
    "    \n",
    "    labels = []\n",
    "    labels.append(\"seed({}) labels: {}\".format(seed['id_'], getlabels(seed)))\n",
    "    \n",
    "    for k in range(1, len(axes)):\n",
    "        axes[k].set_title(\"{:.3g}\".format(score(results[k-1])))\n",
    "        axes[k].imshow(results[k-1]['image'], cmap='gray')\n",
    "        \n",
    "    for i,result in enumerate(results): \n",
    "        labels.append(\"doc({}) labels: {}\".format(result['id_'], getlabels(result)))\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    for label in labels:\n",
    "        print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing the label of each seed with its 8 nearest neighbors.\n",
    "for seed in documents[:32]:\n",
    "    def score(doc):\n",
    "        if doc['id_'] == seed['id_']:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return kl_matrix[seed['id_'], doc['id_']]\n",
    "\n",
    "    results = heapq.nsmallest(7, documents, key=score)\n",
    "    print(\"seed({}) labels: {}\".format(seed['id_'], getlabels(seed)))\n",
    "    for i,result in enumerate(results):\n",
    "        print(\"doc({}) labels: {}\".format(result['id_'], getlabels(result)))\n",
    "    \n",
    "    print(\"---------------------------\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of squares distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    return 0.5*np.sum((a-b)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = np.zeros((len(documents), len(documents)))\n",
    "\n",
    "for k, d1 in enumerate(documents):\n",
    "    for d2 in documents:\n",
    "        distance_matrix[d1['id_'], d2['id_']] = distance(d1['mu'], d2['mu'])\n",
    "        \n",
    "    if not (k+1)%24:\n",
    "        print(',', end='', flush=True)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for seed in documents[:32]:\n",
    "    def score(doc):\n",
    "        if doc['id_'] == seed['id_']:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return distance_matrix[seed['id_'], doc['id_']]\n",
    "\n",
    "    results = heapq.nsmallest(7, documents, key=score)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 8, figsize=(12, 2), subplot_kw={'xticks': [], 'yticks': []})\n",
    "    \n",
    "    axes[0].set_title(\"seed {}\".format(seed['id_']))\n",
    "    axes[0].imshow(np.clip(seed['image']+0.5, 0.0, 1.0), cmap='gray')\n",
    "    \n",
    "    for k in range(1, len(axes)):\n",
    "        axes[k].set_title(\"{:.3g}\".format(score(results[k-1])))\n",
    "        axes[k].imshow(np.clip(results[k-1]['image']+0.5, 0.0, 1.0), cmap='gray')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in documents[:32]:\n",
    "    def score(doc):\n",
    "        if doc['id_'] == seed['id_']:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return distance_matrix[seed['id_'], doc['id_']]\n",
    "\n",
    "    results = heapq.nsmallest(7, documents, key=score)\n",
    "    print(\"seed({}) labels: {}\".format(seed['id_'], getlabels(seed)))\n",
    "    for i,result in enumerate(results):\n",
    "        print(\"doc({}) labels: {}\".format(result['id_'], getlabels(result)))\n",
    "    \n",
    "    print(\"---------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_label_percentage(label, dataset):\n",
    "    \n",
    "    dataset_size = len(dataset)\n",
    "    \n",
    "    count = 0\n",
    "    for doc in dataset:\n",
    "        if(label in getlabels(doc)):\n",
    "            count += 1 \n",
    "            \n",
    "    return count/dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in LABEL_KEYS:\n",
    "    percentage = cal_label_percentage(label, documents)\n",
    "    print(\"{:<20s} {}\".format(label,10*percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_NUMBER = 100\n",
    "k = 10\n",
    "mu_embeddings = []\n",
    "for doc in documents:\n",
    "        mu_embeddings.append(doc['mu'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarities(query_id, vectors):\n",
    "    ''' suppose vectors[i, :] is a single vector in your set;\n",
    "        that is, vectors is a numpy array, where each row is normalized\n",
    "        to l2-norm=1\n",
    "        \n",
    "        returns a numpy vector of similarities: the i'th entry is the similarity\n",
    "        between the i'the vector and the query_id vector\n",
    "    '''\n",
    "    return vectors.dot(vectors[query_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''calculate k nearest vectors of a query vector.'''\n",
    "def calculate_knearest(query_vec, vectors, k):\n",
    "\n",
    "    vectors = np.array(vectors, dtype=np.float)  \n",
    "    scores_truth = build_similarities(query_vec, vectors)\n",
    "    topk_truth = heapq.nlargest(k, list(enumerate(scores_truth)), key = operator.itemgetter(1))\n",
    "        \n",
    "    return topk_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013333333333333332\n"
     ]
    }
   ],
   "source": [
    "'''calculate average number of same labels in the k nearest neighbors over QUERY_NUMBER of samples.'''\n",
    "\n",
    "def neighbor_labels_accuracy(embedding_vecs, k):\n",
    "\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    sample_vecs_index = np.random.choice(len(embedding_vecs), QUERY_NUMBER)\n",
    "    avg = 0\n",
    "    avg_per_sample = 0\n",
    "    for i in range(QUERY_NUMBER):\n",
    "\n",
    "        count = 0\n",
    "        topk_neighbors = calculate_knearest(sample_vecs_index[i], embedding_vecs, k)  \n",
    "        topk_neighbors_indexes = [x[0] for x in topk_neighbors]\n",
    "        query_labels = getlabels(documents[sample_vecs_index[i]])\n",
    "\n",
    "        for j,query_label in enumerate(query_labels):\n",
    "            for neighbor_index in topk_neighbors_indexes:\n",
    "                if query_label in getlabels(documents[neighbor_index]):\n",
    "                    count += 1\n",
    "\n",
    "        avg_per_sample += count/(j+1)\n",
    "\n",
    "    avg =  avg_per_sample/QUERY_NUMBER \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Atelectasis']\n",
      "['No Finding']\n",
      "['Atelectasis', 'Effusion']\n",
      "['Fibrosis', 'Infiltration']\n",
      "['No Finding']\n",
      "['No Finding']\n",
      "['No Finding']\n",
      "['Nodule']\n",
      "['Cardiomegaly']\n",
      "['Effusion', 'Infiltration']\n"
     ]
    }
   ],
   "source": [
    "neighbor_labels_accuracy(mu_embeddings, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_NUMBER = 100\n",
    "def conditional_neighbor_labels_accuracy(conditional_label, embedding_vecs, k):\n",
    "\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    sample_vecs_index = []\n",
    "    avg = 0\n",
    "    avg_per_sample = 0\n",
    "    \n",
    "    while True:\n",
    "        trial_index = np.random.randint(0,len(embedding_vecs))\n",
    "        if conditional_label in getlabels(documents[trial_index]):\n",
    "            sample_vecs_index.append(trial_index)\n",
    "        if len(sample_vecs_index) == QUERY_NUMBER:\n",
    "            break\n",
    "    \n",
    "    results = []\n",
    "    for i in range(QUERY_NUMBER):\n",
    "    \n",
    "        count = 0\n",
    "\n",
    "        topk_neighbors = calculate_knearest(sample_vecs_index[i], embedding_vecs, k)  \n",
    "        topk_neighbors_indexes = [x[0] for x in topk_neighbors]\n",
    "        query_labels = getlabels(documents[sample_vecs_index[i]])\n",
    "\n",
    "        \n",
    "        for neighbor_index in topk_neighbors_indexes:\n",
    "            if conditional_label in getlabels(documents[neighbor_index]):\n",
    "                count += 1\n",
    "        results.append(count) \n",
    "\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in LABEL_KEYS:\n",
    "    x = np.sort(conditional_neighbor_labels_accuracy(label, mu_embeddings, k))\n",
    "    y = np.arange(1,len(x)+1) / len(x)\n",
    "    _ = plt.plot(x,y)\n",
    "    _ = plt.ylabel(label)\n",
    "    plt.margins(0.02)\n",
    "    plt.show()\n",
    "    percentage = cal_label_percentage(label, documents)\n",
    "    print(\"{:<20s} {}\".format(\"Percentage\",10*percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a sprite image consisting of all the images\n",
    "def create_sprite_image(documents, directory):\n",
    "    \"\"\"Returns a sprite image consisting of images passed as argument. Images should be count x width x height\"\"\"\n",
    "    \n",
    "    images = []\n",
    "    for doc in documents:\n",
    "        images.append(doc['image'])\n",
    "\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    \n",
    "    \n",
    "    spriteimage = np.ones((img_h * n_plots ,img_w * n_plots ))\n",
    "    \n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                spriteimage[i * img_h:(i + 1) * img_h,\n",
    "                  j * img_w:(j + 1) * img_w] = this_img\n",
    "                \n",
    "    plt.imsave(directory, spriteimage, cmap='gray')\n",
    "    plt.imshow(sprite_image,cmap='gray')\n",
    "    \n",
    "    return spriteimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a metadata consisting of index and label of our embedding vectors\n",
    "#The Index is simply the index in our embedding matrix. The label is a string of a patient's diseases.\n",
    "def create_metadata(documents, directory):\n",
    "    \n",
    "    with open(directory,'w') as f:\n",
    "        f.write(\"Index\\tLabels\\tFirst_label\\n\")\n",
    "        for index,doc in enumerate(documents):\n",
    "            f.write(\"%d\\t%s\\t%s\\n\" % (index, getlabels_short(doc), getlabels(doc)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprite_image = create_sprite_image(documents, SPRITE_DIR)\n",
    "metadata = create_metadata(documents, META_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed embedding variables into feed into the visualizer\n",
    "mu_embedding = []\n",
    "sigma_embedding = []\n",
    "embeddings = []\n",
    "embedding_names = []\n",
    "\n",
    "for doc in documents:\n",
    "        mu_embedding.append(doc['mu'].tolist())\n",
    "embeddings.append(mu_embedding)\n",
    "embedding_names.append('mu')\n",
    "\n",
    "for doc in documents:\n",
    "        sigma_embedding.append(doc['sigma'].tolist())\n",
    "embeddings.append(sigma_embedding)\n",
    "embedding_names.append('sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify what variable you want to project, what the metadata path is (the names and classes),\n",
    "#and where you save the sprites\n",
    "summary_writer = tf.summary.FileWriter(VIS_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "for i,e in enumerate(embeddings):\n",
    "    \n",
    "    embedding_var = tf.Variable(e, name=embedding_names[i])\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "\n",
    "    # Specify where you find the metadata\n",
    "    embedding.metadata_path = 'metadata.tsv' #'metadata.tsv'\n",
    "\n",
    "    # Specify where you find the sprite (we will create this later)\n",
    "    embedding.sprite.image_path = 'sprite.png' #'sprite.png'\n",
    "    embedding.sprite.single_image_dim.extend([256,256])\n",
    "\n",
    "# Say that you want to visualise the embeddings\n",
    "projector.visualize_embeddings(summary_writer, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensorboard loads the saved variable from the saved graph. \n",
    "#Initialise a session and variables, and save them in your logging directory.\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(VIS_DIR, \"model3.ckpt\"), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
