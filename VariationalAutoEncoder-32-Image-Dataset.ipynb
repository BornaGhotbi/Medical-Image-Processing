{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Built using guidance from https://arxiv.org/pdf/1512.09300.pdf\n",
    "\n",
    "Features:\n",
    "  * Uses ELU activations\n",
    "  * Deconvolution uses upscaling unpool layer before affine operator, rather than spacing with zeros\n",
    "  * Batch normalization after each transformation\n",
    "  * Dropout layer after activation\n",
    "  * abs-sum image loss rather than cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Best result so far is 10 epochs of the first training batch, with the prior and the prediction weighted equally.\n",
    "\n",
    "Running another 10 epochs doesn't hurt the similarity results, but it does make the reconstructions worse.\n",
    "\n",
    "Not quite as good after 10 epochs with regularization=0.1 (down-weighted prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running TensorFlow version 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    "print(\"running TensorFlow version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control memory usage\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report OOM details\n",
    "\n",
    "run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_ROOT = '../../data/'\n",
    "\n",
    "RUN_NAME = 'vae/vae_005'\n",
    "SUMMARY_DIR = os.path.join(LOG_ROOT, 'logs', RUN_NAME)\n",
    "MODEL_DIR = os.path.join(LOG_ROOT, 'models', RUN_NAME)\n",
    "MODEL_GRAPH = os.path.join(MODEL_DIR, 'vae.meta')\n",
    "MODEL_PREFIX = os.path.join(MODEL_DIR, 'vae')\n",
    "\n",
    "DATA_SIZE = 'all_packs'\n",
    "EXPT_NAME = 'expt_005'\n",
    "VIS_NAME = 'vis_001'\n",
    "DATA_ROOT = '/var/data/processed'\n",
    "\n",
    "EXPT_DIR = os.path.join(DATA_ROOT, EXPT_NAME, 'data')\n",
    "TFRECORDS_DIR = os.path.join('/var/data/original/tfrecords/', DATA_SIZE)\n",
    "EMBEDDINGS_DIR = os.path.join(EXPT_DIR, 'embeddings')\n",
    "ENCODED_IMAGES_DIR =  os.path.join(EXPT_DIR, 'images')\n",
    "\n",
    "TRAIN_IMAGES = '/var/data/original/data/images_1pack/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_image(path, size):\n",
    "    ''' load grayscale image from file; resize if necessary\n",
    "    '''\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(\"empty image: {}\".format(path))\n",
    "\n",
    "    if size:\n",
    "        img = cv2.resize(img, (size,size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "\n",
    "data = []\n",
    "filenames = []\n",
    "for i,image_path in enumerate(glob.glob(os.path.join(TRAIN_IMAGES,'*'))):\n",
    "    filenames.append(image_path[-16:-4])\n",
    "    data.append(_load_image(image_path, 256))\n",
    "    if(i==100):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_256_pattern = re.compile('^train_(?P<block_id>[0-9]{3}).tfrecords')\n",
    "validate_256_pattern = re.compile('^validate_(?P<block_id>[0-9]{3}).tfrecords')\n",
    "test_256_pattern = re.compile('^test_(?P<block_id>[0-9]{3}).tfrecords')\n",
    "golden_256_pattern = re.compile('golden_(?P<block_id>[0-9]{3}).tfrecords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ALL_TFRECORDS = os.listdir(TFRECORDS_DIR)\n",
    "def get_sorted_records(pattern, directory):\n",
    "     return [ \\\n",
    "         os.path.join(directory, _file) \\\n",
    "         for _file in \\\n",
    "         sorted([_m[0] for _m in \\\n",
    "             [pattern.match(_f) for _f in os.listdir(directory)] if _m]) \\\n",
    "     ]\n",
    "\n",
    "GOLDEN_TFRECORDS = get_sorted_records(golden_256_pattern, TFRECORDS_DIR)\n",
    "TRAIN_TFRECORDS = get_sorted_records(train_256_pattern, TFRECORDS_DIR)\n",
    "VALIDATE_TFRECORDS = get_sorted_records(validate_256_pattern, TFRECORDS_DIR)\n",
    "TEST_TFRECORDS = get_sorted_records(test_256_pattern, TFRECORDS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['/var/data/original/tfrecords/all_packs/train_003.tfrecords'],\n",
       " ['/var/data/original/tfrecords/all_packs/validate_003.tfrecords'],\n",
       " ['/var/data/original/tfrecords/all_packs/golden_003.tfrecords'],\n",
       " ['/var/data/original/tfrecords/all_packs/test_003.tfrecords'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "TRAIN_TFRECORDS, VALIDATE_TFRECORDS,GOLDEN_TFRECORDS, TEST_TFRECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(SUMMARY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _augment(filename, image):\n",
    "    '''Placeholder for data augmentation\n",
    "    '''\n",
    "    image = tf.reshape(image, [256, 256, 1])\n",
    "    return filename, image\n",
    "\n",
    "\n",
    "def _normalize(filename, image):\n",
    "    '''Convert `image` from [0, 255] -> [-0.5, 0.5] floats\n",
    "    '''\n",
    "    image = tf.cast(image, tf.float32) * (1. / 255) - 0.5\n",
    "    return filename, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(filenames, images, batch_size, num_epochs):\n",
    "    ''' Reads input data num_epochs times or forever if num_epochs is None\n",
    "        returns dataset, iterator pair\n",
    "    '''\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        # TFRecordDataset opens a binary file and reads one record at a time.\n",
    "        # `filename` could also be a list of filenames, which will be read in order.\n",
    "       \n",
    "        def gen():\n",
    "            for i,_ in enumerate(filenames):\n",
    "                yield(filenames[i], images[i])\n",
    "                \n",
    "        dataset = tf.data.Dataset.from_generator(gen,\n",
    "                                                 (tf.string, tf.float32),\n",
    "                                                 (tf.TensorShape([]), tf.TensorShape([256,256])))\n",
    "\n",
    "        '''def generator():\n",
    "            for i,f in enumerate(filenames):\n",
    "                yield tuple(f, images[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        #dataset = tf.data.Dataset.from_generator(lambda: images, tf.float32, tf.TensorShape([256,256]))\n",
    "        dataset = tf.data.Dataset.from_generator(generator, (tf.string, tf.float32) \n",
    "                                                 (tf.TensorShape([None]), tf.TensorShape([256,256])))'''\n",
    "        \n",
    "        # The map transformation takes a function and applies it to every element\n",
    "        # of the dataset.\n",
    "        \n",
    "        #dataset = dataset.map(_decode)\n",
    "        #dataset = dataset.shard(num_shards, shard_index)\n",
    "        #dataset = dataset.filter(_filter)\n",
    "        dataset = dataset.map(_augment)\n",
    "        dataset = dataset.map(_normalize)\n",
    "\n",
    "        # The shuffle transformation uses a finite-sized buffer to shuffle elements\n",
    "        # in memory. The parameter is the number of elements in the buffer. For\n",
    "        # completely uniform shuffling, set the parameter to be the same as the\n",
    "        # number of elements in the dataset.\n",
    "        dataset = dataset.shuffle(1000 + 3 * batch_size)\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    return dataset, iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "DROPOUT = 0.7\n",
    "REGULARIZATION = 0.1\n",
    "\n",
    "DISPLAY_EVERY = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summary(x, name):\n",
    "    with tf.variable_scope(name):\n",
    "        mean = tf.reduce_mean(x)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(x - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(x))\n",
    "        tf.summary.scalar('min', tf.reduce_min(x))\n",
    "        tf.summary.histogram('histogram', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpool operation doesn't yet exist in TF\n",
    "\n",
    "def unpool_op(x, stride, name='unpool'):\n",
    "\n",
    "    with tf.name_scope(name) as scope:\n",
    "\n",
    "        if stride==1:\n",
    "            return x\n",
    "\n",
    "        shape = x.get_shape().as_list()\n",
    "        dim = len(shape[1:-1])\n",
    "        out = (tf.reshape(x, [-1] + shape[-dim:]))\n",
    "        for i in range(dim, 0, -1):\n",
    "            out = tf.concat([out]*stride, i)\n",
    "        out_size = [-1] + [s * stride for s in shape[1:-1]] + [shape[-1]]\n",
    "        out = tf.reshape(out, out_size, name=scope)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_layer(x, dims, stride, train, bias=None, name='conv', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        if bias is None:\n",
    "             conv = tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1], padding='SAME', name='conv')\n",
    "        else:\n",
    "             conv = tf.nn.bias_add(tf.nn.conv2d(x, weights, strides=[1, stride, stride, 1],\n",
    "                        padding='SAME'), biases, name='conv')\n",
    "        normalized = tf.layers.batch_normalization(conv, axis=3, training=train,\n",
    "                    name='spatial_batch_norm')        \n",
    "        activations = activation(normalized, name='activation')\n",
    "        activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', normalized)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconvolution_layer(x, dims, stride, train, bias=None, name='deconv', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        unpool = unpool_op(x, stride, name='unpool')\n",
    "        if bias is None:\n",
    "            deconv = tf.nn.conv2d(unpool, weights, strides=[1, 1, 1, 1], padding='SAME', name='deconv')\n",
    "        else:\n",
    "            deconv = tf.nn.bias_add(tf.nn.conv2d(unpool, weights, strides=[1, 1, 1, 1],\n",
    "                        padding='SAME'), biases, name='deconv')\n",
    "        normalized = tf.layers.batch_normalization(deconv, axis=3, training=train,\n",
    "                    name='spatial_batch_norm')        \n",
    "        activations = activation(deconv, name='activation')\n",
    "        activations = tf.layers.dropout(activations, rate=DROPOUT, training=train, name='dropout')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', deconv)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(x, dims, train, bias=None, name='fc', activation=tf.nn.elu):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # Parameters\n",
    "        weights = tf.get_variable('w', dims,\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "        if bias is not None:\n",
    "            biases = tf.get_variable('b', [dims[-1]],\n",
    "                        initializer=tf.random_normal_initializer())\n",
    "\n",
    "        # Layer structure\n",
    "        if bias is None:\n",
    "            dense = tf.matmul(x, weights, name='dense')\n",
    "        else:\n",
    "            dense = tf.nn.bias_add(tf.matmul(x, weights), biases, name='dense')\n",
    "\n",
    "        normalized = tf.layers.batch_normalization(dense, axis=1, training=train,\n",
    "                    name='batch_norm')\n",
    "        activations = activation(normalized, name='activation')\n",
    "\n",
    "        # Variable summaries\n",
    "        variable_summary(weights, 'weights')\n",
    "        if bias is not None:\n",
    "            variable_summary(biases, 'biases')\n",
    "        tf.summary.histogram('pre-activations', normalized)\n",
    "        tf.summary.histogram('activations', activations)\n",
    "\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_sample(mean, stddev, name):\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "\n",
    "        # mean is unconstrained; stddev must be strictly positive\n",
    "        stddev = 1e-6 + tf.nn.softplus(stddev)\n",
    "\n",
    "        # actually sample\n",
    "        z = mean + stddev * tf.random_normal(tf.shape(mean), 0, 1, dtype=tf.float32)\n",
    "\n",
    "        # Variable summaries\n",
    "        tf.summary.histogram('mean', mean)\n",
    "        tf.summary.histogram('stddev', stddev)\n",
    "        tf.summary.histogram('z', z)\n",
    "\n",
    "        return mean, stddev, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, xhat, mu, sigma):\n",
    "\n",
    "    with tf.variable_scope('loss'):\n",
    "        # Structure\n",
    "        pred = tf.losses.absolute_difference(x, xhat,\n",
    "                reduction=tf.losses.Reduction.MEAN)\n",
    "\n",
    "        # offsetx = x + 0.5\n",
    "        # pred = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        #         labels=offsetx, logits=xhat))\n",
    "\n",
    "        KLdiv = 0.5 * tf.reduce_mean(tf.square(mu) + \\\n",
    "                    tf.square(sigma) - tf.log(1e-8 + tf.square(sigma)) - 1)\n",
    "\n",
    "        loss = tf.add(REGULARIZATION * KLdiv, pred)\n",
    "\n",
    "        # Summaries\n",
    "        tf.summary.scalar('prediction', pred)\n",
    "        tf.summary.scalar('prior', KLdiv)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "    return loss, pred, KLdiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(img, train):\n",
    "\n",
    "    with tf.variable_scope('encoder'):\n",
    "\n",
    "        # convolution\n",
    "        conv1 = convolution_layer(img, [5, 5, 1, 64], 2, train, name='conv1')\n",
    "        conv2 = convolution_layer(conv1, [5, 5, 64, 128], 2, train, name='conv2')\n",
    "        conv3 = convolution_layer(conv2, [5, 5, 128, 256], 2, train, name='conv3')\n",
    "\n",
    "        # transition\n",
    "        conv3 = tf.reshape(conv3, [-1, 32*32*256], name='reshape1')\n",
    "\n",
    "        # dense output\n",
    "        fc1 = dense_layer(conv3, [32*32*256, 64], train,\n",
    "                activation=tf.identity, name='fc1')\n",
    "\n",
    "        # sample\n",
    "        mu, sigma, z = gaussian_sample(fc1[:, :32], fc1[:, 32:], name='output')\n",
    "\n",
    "    return mu, sigma, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, train):\n",
    "\n",
    "    with tf.variable_scope('decoder'):\n",
    "\n",
    "        # dense input\n",
    "        fc1 = dense_layer(z, [32, 32*32*256], train, name='fc1')\n",
    "\n",
    "        # transition\n",
    "        fc1 = tf.reshape(fc1, [-1, 32, 32, 256], name='reshape1')\n",
    "\n",
    "        # deconvolution\n",
    "        deconv1 = deconvolution_layer(fc1, [5, 5, 256, 128], 2, train,\n",
    "                            name='deconv1')\n",
    "        deconv2 = deconvolution_layer(deconv1, [5, 5, 128, 64], 2, train, \n",
    "                            name='deconv2')\n",
    "        deconv3 = deconvolution_layer(deconv2, [5, 5, 64, 32], 2, train,\n",
    "                            name='deconv3')\n",
    "        logits = deconvolution_layer(deconv3, [5, 5, 32, 1], 1, train,\n",
    "                            activation=tf.identity, name='logits')\n",
    "\n",
    "        # put into image range for display\n",
    "        with tf.name_scope('range'):\n",
    "            xhat = 0.5 * tf.nn.tanh(logits)\n",
    "\n",
    "    return xhat, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_alternative(z, train):\n",
    "\n",
    "    with tf.variable_scope('decoder'):\n",
    "\n",
    "        # dense input\n",
    "        fc1 = dense_layer(z, [32, 32*32*256], train, name='fc1')\n",
    "\n",
    "        # transition\n",
    "        fc1 = tf.reshape(fc1, [-1, 32, 32, 256], name='reshape1')\n",
    "\n",
    "        # deconvolution\n",
    "        deconv1 = deconvolution_layer(fc1, [5, 5, 256, 128], 2, train,\n",
    "                            name='deconv1')\n",
    "        deconv1a = deconvolution_layer(deconv1, [5, 5, 128, 128], 2, train,\n",
    "                            name='deconv1a')\n",
    "        deconv2 = deconvolution_layer(deconv1a, [5, 5, 128, 64], 2, train, \n",
    "                            name='deconv2')\n",
    "        deconv3 = deconvolution_layer(deconv2, [5, 5, 64, 32], 2, train,\n",
    "                            name='deconv3')\n",
    "        logits = deconvolution_layer(deconv3, [5, 5, 32, 1], 1, train,\n",
    "                            activation=tf.identity, name='logits')\n",
    "\n",
    "        # put into image range for display\n",
    "        with tf.name_scope('range'):\n",
    "            xhat = 0.5 * tf.nn.tanh(logits)\n",
    "\n",
    "    return xhat, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    format=\"%(asctime)s [train/initialize] %(levelname)-8s %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "NOW_STR = datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "RUN_DESC = \"cross-entropy loss, 256x256 images, no bias\"\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-06T22:19:57+0000 [train/initialize] INFO     initializing run: vae/vae_005\n",
      "2018-07-06T22:20:00+0000 [train/initialize] INFO       step      loss      recon     reg\n",
      "2018-07-06T22:20:06+0000 [train/initialize] INFO          0     0.222     0.211     0.108\n",
      "2018-07-06T22:20:06+0000 [train/initialize] INFO     saving graph\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def initialize():\n",
    "\n",
    "    logging.info(\"initializing run: {}\".format(RUN_NAME))\n",
    "\n",
    "    # write a note regarding this run\n",
    "    os.makedirs(SUMMARY_DIR, exist_ok=True)\n",
    "    with open(os.path.join(SUMMARY_DIR, \"description.txt\"), 'w') as fh:\n",
    "        fh.write(NOW_STR+\" \"+RUN_DESC)\n",
    "\n",
    "    # Control memory usage\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    # Report OOM details\n",
    "    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "    # Build graph\n",
    "    with tf.Graph().as_default() as graph:\n",
    "\n",
    "        # Repeatable results\n",
    "        tf.set_random_seed(RANDOM_SEED)\n",
    "\n",
    "        # Get Data\n",
    "        train_dataset, train_iterator = inputs(filenames=filenames, images=data,\n",
    "                batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "        # Data placeholder\n",
    "        data_handle = tf.placeholder(tf.string, shape=[])\n",
    "        iterator = tf.data.Iterator.from_string_handle(\n",
    "            data_handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "        \n",
    "        filename, image = iterator.get_next()\n",
    "        train = tf.placeholder(tf.bool)\n",
    "\n",
    "        # Global counter\n",
    "        global_step = tf.train.get_or_create_global_step(graph)\n",
    "\n",
    "        # Dropout\n",
    "        dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "        # Autoencoder\n",
    "        mu, sigma, z = encoder(image, train)\n",
    "        xhat, logits = decoder(z, train)\n",
    "        loss, recon, reg = evaluate(image, xhat, mu, sigma)\n",
    "\n",
    "        # Training branch - control dependencies so batchnorm params are updated\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\\\n",
    "                .minimize(loss, global_step=global_step, name='optimizer')\n",
    "\n",
    "        # Log output for Tensorboard\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_summary_logger = tf.summary.FileWriter(SUMMARY_DIR+'/train',\n",
    "                        graph=graph, flush_secs=30)\n",
    "\n",
    "        # Initializer\n",
    "        init_variables = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "        # Save state\n",
    "        tf.add_to_collection('optimizer', optimizer)\n",
    "\n",
    "        tf.add_to_collection('filename', filename)\n",
    "        tf.add_to_collection('image', image)\n",
    "\n",
    "        tf.add_to_collection('mu', mu)\n",
    "        \n",
    "        tf.add_to_collection('sigma', sigma)\n",
    "        tf.add_to_collection('xhat', xhat)\n",
    "\n",
    "        tf.add_to_collection('loss', loss)\n",
    "        tf.add_to_collection('recon', recon)\n",
    "        tf.add_to_collection('reg', reg)\n",
    "\n",
    "        tf.add_to_collection('data_handle', data_handle)\n",
    "        tf.add_to_collection('train', train)\n",
    "\n",
    "        tf.add_to_collection('merged', merged)\n",
    "\n",
    "        writer = tf.train.Saver()\n",
    "\n",
    "        # Run one step: this initializes the graph and saves our starting statistics\n",
    "        with tf.Session(config=config) as session:\n",
    "\n",
    "            session.run(init_variables)\n",
    "\n",
    "            train_handle = session.run(train_iterator.string_handle())\n",
    "\n",
    "            # Output header\n",
    "            logging.info(\"  step      loss      recon     reg\")\n",
    "\n",
    "            _, step = session.run([optimizer, global_step],\n",
    "                    feed_dict = { data_handle: train_handle, train: 1 },\n",
    "                    options = run_options)\n",
    "\n",
    "            loss_, recon_, reg_, summary = \\\n",
    "                session.run([loss, recon, reg, merged],\n",
    "                           feed_dict = { data_handle: train_handle, train: 0 })\n",
    "            train_summary_logger.add_summary(summary, step)\n",
    "\n",
    "            logging.info(\"{: 6d} {:9.3g} {:9.3g} {:9.3g}\".format(step, loss_, recon_, reg_))\n",
    "\n",
    "            # Save graph\n",
    "            logging.info(\"saving graph\")\n",
    "            writer.save(session, MODEL_PREFIX, global_step=step, write_meta_graph=False)\n",
    "            writer.export_meta_graph(MODEL_GRAPH)\n",
    "            \n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='initialize training graph')\n",
    "    initialize()\n",
    "    sys.exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/vae/vae_005/vae-0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-06T22:20:11+0000 [train/initialize] INFO     Restoring parameters from ../../data/models/vae/vae_005/vae-0\n",
      "2018-07-06T22:20:12+0000 [train/initialize] INFO       step      loss      recon     reg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    \n",
    "    # Repeatable results\n",
    "    tf.set_random_seed(0)\n",
    "\n",
    "    # Get Data\n",
    "    _, train_iterator = inputs(filenames, images=data, batch_size=BATCH_SIZE, num_epochs=NUM_EPOCHS)\n",
    "        \n",
    "    # Log output for Tensorboard\n",
    "    train_summary_logger = tf.summary.FileWriter(SUMMARY_DIR+'/train', flush_secs=30)\n",
    "\n",
    "    # Run\n",
    "    with tf.Session(config=config) as session:\n",
    "\n",
    "        # restore\n",
    "        reader = tf.train.import_meta_graph(MODEL_GRAPH)\n",
    "        reader.restore(session, tf.train.latest_checkpoint(MODEL_DIR))\n",
    "\n",
    "        # must be called after reader so that the graph is populated\n",
    "        writer = tf.train.Saver()\n",
    "\n",
    "        # get references to graph endpoints\n",
    "        global_step = tf.train.get_global_step(graph)\n",
    "\n",
    "        optimizer = tf.get_collection('optimizer')[0]\n",
    "        loss = tf.get_collection('loss')[0]\n",
    "        recon = tf.get_collection('recon')[0]\n",
    "        reg = tf.get_collection('reg')[0]\n",
    "\n",
    "        data_handle = tf.get_collection('data_handle')[0]\n",
    "        train = tf.get_collection('train')[0]\n",
    "\n",
    "        merged = tf.get_collection('merged')[0]\n",
    "\n",
    "        train_handle = session.run(train_iterator.string_handle())\n",
    "\n",
    "        # Output header\n",
    "        logging.info(\"  step      loss      recon     reg\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                _, step = session.run([optimizer, global_step], \n",
    "                            feed_dict = { data_handle: train_handle, train: 1 })\n",
    "\n",
    "                if not step%DISPLAY_EVERY:\n",
    "\n",
    "                    loss_, recon_, reg_, summary = session.run([loss, recon, reg, merged],\n",
    "                            feed_dict = { data_handle: train_handle, train: 0 })\n",
    "                    train_summary_logger.add_summary(summary, step)\n",
    "\n",
    "                    logging.info(\"{: 6d} {:9.3g} {:9.3g} {:9.3g}\".format(\n",
    "                        step, loss_, recon_, reg_))\n",
    "\n",
    "                    writer.save(session, MODEL_PREFIX, global_step=step, write_meta_graph=False)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"done\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Try out the autoencoder by running it on some test set samples.\n",
    "\n",
    "For a collection of test images:\n",
    "\n",
    "1. Create (image, label, mu, sigma) tuples\n",
    "1. For a seed image, compute the 10 nearest images using (mu, sigma)\n",
    "1. View the nearby images and their labels, comparing them to the seed image\n",
    "\n",
    "If the VAE has worked as expected, we should find that the nearby images match the seed visually, and perhaps even match according to their labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gen_documents(filenames, images, RUN_NAME, BATCH_SIZE):\n",
    "    \n",
    "    SUMMARY_DIR = os.path.join(LOG_ROOT, 'logs', RUN_NAME)\n",
    "    dir_name = SUMMARY_DIR + '/train'\n",
    "    MODEL_DIR = os.path.join(LOG_ROOT, 'models', RUN_NAME)\n",
    "    MODEL_GRAPH = os.path.join(MODEL_DIR, 'vae.meta')\n",
    "    \n",
    "    \n",
    "    # Store the documents\n",
    "    documents = []\n",
    "    def extend(docs, m, s, xh, f, i):\n",
    "        start_id = len(docs)\n",
    "        docs.extend([\n",
    "            {\n",
    "                'filename':f_.decode('ascii') ,\n",
    "                'image': i_.reshape(256, 256)+0.5,\n",
    "                'sigma': s_,\n",
    "                'mu': m_,\n",
    "                'xhat': y_.reshape(256, 256)+0.5\n",
    "            }\n",
    "            for k, (m_, s_, y_, f_, i_) in enumerate(zip(m, s, xh, f, i))\n",
    "        ])\n",
    "        return docs\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "\n",
    "        # Repeatable results\n",
    "        tf.set_random_seed(0)\n",
    "\n",
    "        # Get Data\n",
    "        dataset, iterator = inputs(filenames = filenames, images = images, batch_size=BATCH_SIZE, num_epochs=1)\n",
    "        # Log output for Tensorboard\n",
    "        summary_logger = tf.summary.FileWriter(dir_name, flush_secs=30)\n",
    "\n",
    "        # Run\n",
    "        with tf.Session(config=config) as session:\n",
    "\n",
    "            # restore\n",
    "            reader = tf.train.import_meta_graph(MODEL_GRAPH)\n",
    "            reader.restore(session, tf.train.latest_checkpoint(MODEL_DIR))\n",
    "\n",
    "            # get references to graph endpoints\n",
    "            filename = tf.get_collection('filename')[0]\n",
    "            image = tf.get_collection('image')[0]\n",
    "\n",
    "            mu = tf.get_collection('mu')[0]\n",
    "            sigma = tf.get_collection('sigma')[0]\n",
    "            xhat = tf.get_collection('xhat')[0]\n",
    "\n",
    "            merged = tf.get_collection('merged')[0]\n",
    "\n",
    "            data_handle = tf.get_collection('data_handle')[0]\n",
    "            train = tf.get_collection('train')[0]\n",
    "            handle = session.run(iterator.string_handle())\n",
    "            \n",
    "            step = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    mu_, sigma_, xhat_, filename_,  image_, summary = \\\n",
    "                        session.run([mu, sigma, xhat, filename, image, merged],\n",
    "                                feed_dict = { data_handle: handle, train: 0 })\n",
    "                    documents = extend(documents, mu_, sigma_, xhat_,filename_, image_)\n",
    "                    step += 1\n",
    "                    summary_logger.add_summary(summary, step)                        \n",
    "                    print(\"{}.\".format(step), end=\"\", flush=True)\n",
    "        \n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    print(\".done\")\n",
    "                    break\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../data/models/vae/vae_005/vae-0\n",
      "1.2.3.4..done\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = 'vae/vae_005'\n",
    "BATCH_SIZE = 32\n",
    "documents = gen_documents(filenames, data, RUN_NAME, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBSET == \"golden\":\n",
    "    golden_documents = gen_documents(GOLDEN_TFRECORDS, '/golden', 1)\n",
    "elif SUBSET == \"validate\":\n",
    "    validate_documents = gen_documents(VALIDATE_TFRECORDS, '/validate')\n",
    "elif SUBSET == \"test\":\n",
    "    test_documents = gen_documents(TEST_TFRECORDS, '/test')\n",
    "elif SUBSET == \"train\":\n",
    "    train_documents = gen_documents(TRAIN_TFRECORDS, '/train', 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import scipy.misc as misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_json(documents):\n",
    "    \n",
    "    for doc in documents:\n",
    "        json_item = {\n",
    "            'id':doc['id_'],\n",
    "            'filename': doc['filename'],\n",
    "            'subset': SUBSET,\n",
    "            'encodedname': doc['filename'],\n",
    "            'labels': doc['labels'].tolist(),\n",
    "            'age': int(doc['age']),\n",
    "            'gender': doc['gender'],\n",
    "            'view': doc['view'],\n",
    "            'mu':doc['mu'].tolist(),\n",
    "            'sigma':doc['sigma'].tolist()\n",
    "        }\n",
    "\n",
    "        JSON_DIR = os.path.join(EMBEDDINGS_DIR, doc['filename'][:12] + \".json\")\n",
    "        with open(JSON_DIR, 'w') as outfile:\n",
    "            json.dump(json_item, outfile, separators=(',', ':'), indent = 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBSET == \"golden\":\n",
    "    gen_json(golden_documents)\n",
    "\n",
    "elif SUBSET == \"validate\":\n",
    "    gen_json(validate_documents)\n",
    "    \n",
    "elif SUBSET == \"test\":\n",
    "    gen_json(test_documents)\n",
    "    \n",
    "elif SUBSET == \"train\":\n",
    "    gen_json(train_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save the encoded 256x256 vectors as png file\n",
    "def save_images(documents):\n",
    "    for doc in documents:\n",
    "\n",
    "        path = os.path.join(ENCODED_IMAGES_DIR, doc['filename'])\n",
    "        misc.imsave(path, doc['xhat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SUBSET == \"golden\":\n",
    "    save_images(golden_documents)\n",
    "\n",
    "elif SUBSET == \"validate\":\n",
    "    save_images(validate_documents)\n",
    "    \n",
    "elif SUBSET == \"test\":\n",
    "    save_images(test_documents)\n",
    "    \n",
    "elif SUBSET == \"train\":\n",
    "    save_images(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(train_documents):\n",
    "    f = 0\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
